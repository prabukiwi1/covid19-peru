{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obteniendo el TOTAL de vacunados y fallecidos por COVID-19 por cada semana epidemiológica de todo el Perú\n",
    "\n",
    "En este notebook se busca obtener un dataset con el total de **fallecidos** y vacunados **(dosis 1,2 y 3)** por cada **año** y **semana epidemiológica** de todo el Perú. \n",
    "\n",
    "Se considera como **completamente vacunado** a todas las personas reciberon 2 dosis de vacunación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Cargar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask.dataframe as dd\n",
    "from epiweeks import Week\n",
    "\n",
    "import functions as fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Procesar el dataset de fallecidos\n",
    "\n",
    "El dataset de fallecidos será procesado con la librería **Pandas**.\n",
    "\n",
    "### 1.1. Leer y procesar el dataset\n",
    "\n",
    "Como se sabe que cada fila representa a una persona, solamente se toma la columna **'fecha de fallecimiento'**.\n",
    "\n",
    "Se añaden 3 columnas. El año, la semana epidemiológica correspondiente y un contador para contar cada caso de fallecimiento por COVID-19. Se elimina la columna **'fecha_fallecimiento'**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EDAD_DECLARADA</th>\n",
       "      <th>DEPARTAMENTO</th>\n",
       "      <th>year</th>\n",
       "      <th>epi_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77</td>\n",
       "      <td>ANCASH</td>\n",
       "      <td>2021</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70</td>\n",
       "      <td>LIMA</td>\n",
       "      <td>2021</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>LIMA</td>\n",
       "      <td>2021</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59</td>\n",
       "      <td>AYACUCHO</td>\n",
       "      <td>2021</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55</td>\n",
       "      <td>LIMA</td>\n",
       "      <td>2021</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EDAD_DECLARADA DEPARTAMENTO  year  epi_week\n",
       "0              77       ANCASH  2021        47\n",
       "1              70         LIMA  2021        17\n",
       "2              70         LIMA  2021        17\n",
       "3              59     AYACUCHO  2021        17\n",
       "4              55         LIMA  2021        16"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Leer el dataset\n",
    "url_fal = 'RawData/fallecidos_covid.csv'\n",
    "fal_col = ['FECHA_FALLECIMIENTO', 'DEPARTAMENTO', 'EDAD_DECLARADA']\n",
    "df_fal = pd.read_csv(url_fal, sep = ';', usecols = fal_col, dtype = {'FECHA_FALLECIMIENTO':'int32',\n",
    "                                                                     'EDAD_DECLARADA': 'int8'})\n",
    "del url_fal, fal_col\n",
    "\n",
    "# Transformar a formato fecha y convertir a semana epidemiológia y año\n",
    "df_fal.loc[:,'FECHA_FALLECIMIENTO'] = pd.to_datetime(df_fal['FECHA_FALLECIMIENTO'], format = '%Y%m%d')\n",
    "fn.date_to_epiweek(df_fal,'FECHA_FALLECIMIENTO') \n",
    "del df_fal['FECHA_FALLECIMIENTO']\n",
    "\n",
    "#df_fal['SEXO'].replace({'MASCULINO': 0,'FEMENINO':1}, inplace=True)\n",
    "#df_fal = df_fal[df_fal['SEXO'].apply(lambda x: str(x).isdigit())]\n",
    "\n",
    "df_fal = df_fal.astype({'year': 'int16', 'epi_week': 'int8'})\n",
    "df_fal.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se cuenta cada caso de la variable **'fallecidos'** respecto al año y semana epidemiológica. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>total_fallecidos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th>epi_week</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2020</th>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               total_fallecidos\n",
       "year epi_week                  \n",
       "2020 10                       3\n",
       "     11                       3\n",
       "     12                      36\n",
       "     13                      64\n",
       "     14                     226"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Devuelve un dataframe con el total de FALLECIDOS por año y semana epidemiológica\n",
    "epi_fal = df_fal.groupby(['year', 'epi_week']).count()\n",
    "epi_fal = epi_fal.rename(columns = {'DEPARTAMENTO':'total_fallecidos'})\n",
    "del epi_fal['EDAD_DECLARADA']\n",
    "\n",
    "epi_fal.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtiene un dataframe **'epi_fal'** con el total de fallecidos por año y semana epidemiológica de todo el Perú."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Procesar el dataset de vacunados\n",
    "\n",
    "### 2.1. Leer y procesar el dataset\n",
    "\n",
    "El dataset de vacunados **'TB_VACUNACION_COVID19.csv'** no está incluido en el repositorio de GitHub debido a su excesivo tamaño (~2gb). Sin embargo se puede descargar directamente desde la página de Datos Abiertos de COVID-19 de MINSA, [Vacunación contra la COVID-19](https://www.datosabiertos.gob.pe/dataset/vacunacion) y colocarlo en la dirección RawData.\n",
    "\n",
    "Debido al tamaño del dataset de vacunados y para preservar recursos, no se procesará la información usando **Pandas**. En su lugar se utilizará el paquete **Dask**. El dataset no será un **pandas dataframe** si no un **dask dataframe** el cual está separado en n particiones de tipo **pandas dataframe**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dosis</th>\n",
       "      <th>year</th>\n",
       "      <th>epi_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2021</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2021</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2021</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dosis  year  epi_week\n",
       "0      1  2021        49\n",
       "1      2  2021        38\n",
       "2      2  2021        50\n",
       "3      1  2021        47\n",
       "4      1  2021        46"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vac_url = 'RawData/TB_VACUNACION_COVID19.csv'\n",
    "vac_col = ['fecha_vacunacion','dosis']\n",
    "df_vac = dd.read_csv(vac_url, sep = \",\", usecols = vac_col, \n",
    "                     dtype = {'fecha_vacunacion':'int32', 'dosis': 'int8'})\n",
    "del vac_col\n",
    "\n",
    "# Personas con 3 o menos dosis\n",
    "df_vac = df_vac[df_vac['dosis'] <= 3]\n",
    "\n",
    "# Convertimos a formato fecha la columna 'fecha_vacunacion'\n",
    "df_vac = df_vac.assign(fecha_vacunacion = dd.to_datetime(df_vac[\"fecha_vacunacion\"], format = \"%Y%m%d\", \n",
    "                                                         errors=\"coerce\"))\n",
    "\n",
    "# Obtenemos el año y semana epidemiológica en una sola columna\n",
    "df_vac['epi_date'] = df_vac['fecha_vacunacion'].map(lambda date : Week.fromdate(date).isoformat())\n",
    "del df_vac['fecha_vacunacion']\n",
    "\n",
    "# Se separa la columna obtenida en 2, una para el año y otra para la semana epidemiológica\n",
    "df_vac[['year','epi_week']] = df_vac['epi_date'].str.split(\"W\", 1, expand=True)\n",
    "del df_vac['epi_date']\n",
    "\n",
    "# Cambiamos el tipo de variable para consumir menos recursos\n",
    "df_vac['year'] = df_vac['year'].astype('int16')\n",
    "df_vac['epi_week'] = df_vac['epi_week'].astype('int8')\n",
    "\n",
    "df_vac.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Crosstab del número de dosis (1,2 y 3) respecto al año y semana epidemiológica\n",
    "\n",
    "**Nota:** No se puede usar multi-index en pivot_table para dask, debido a eso se crea la función **'crosstab4dask'**. Aún es necesario buscar en dask funciones para iterar todas las particiones más facilmente y optimizar el script **(Pendiente)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crosstab4dask(ddf):\n",
    "    \"\"\"Función que recibe un dask dataframe (ddf) y realiza conteos de variables en cada partición\n",
    "    y devuelve el total por los index que hayamos ingresado, en este caso 'year' y 'epi_week'.\"\"\"\n",
    "    \n",
    "    lst = []  # Lista para almacenar la sumatoria de cada particion\n",
    "\n",
    "    for i in range(0, ddf.npartitions):\n",
    "        ddf = df_vac.partitions[i].compute()\n",
    "        lst.append(pd.crosstab(index=[ddf['year'],ddf['epi_week']], columns = ddf['dosis']))\n",
    "\n",
    "    merged_epivac = pd.concat(lst, axis=1)  # Merge all dfs\n",
    "    del lst\n",
    "\n",
    "    merged_epivac = merged_epivac.fillna(0).astype(np.int64)\n",
    "    merged_epivac = merged_epivac.groupby(level=0, axis=1).sum()\n",
    "    \n",
    "    return merged_epivac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vac_dose = crosstab4dask(df_vac)\n",
    "vac_dose.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtiene un dataset **'vac_dose'** con el número de dosis aplicada por año y semana epidemiológica de todo el Perú."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Procesar el dataset de infectados\n",
    "\n",
    "### 4.1. Leer y procesar el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cas_url = 'RawData/positivos_covid.csv'\n",
    "cas_col = ['FECHA_RESULTADO','EDAD']\n",
    "df_cas = pd.read_csv(cas_url, sep = ';', usecols = cas_col)\n",
    "\n",
    "df_cas.dropna(inplace=True)\n",
    "df_cas = df_cas.astype({'EDAD': 'int8', 'FECHA_RESULTADO': 'int32'})\n",
    "\n",
    "# Agregamos el año y semana epidemilógica de cada fallecido\n",
    "df_cas.loc[:,'FECHA_RESULTADO'] = pd.to_datetime(df_cas['FECHA_RESULTADO'], format = '%Y%m%d')\n",
    "fn.date_to_epiweek(df_cas,'FECHA_RESULTADO') \n",
    "del df_cas['FECHA_RESULTADO']\n",
    "\n",
    "#fn.variable_edad(df_cas, 'EDAD')\n",
    "df_cas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Devuelve un dataframe con el total de CASOS por año y semana epidemiológica\n",
    "epi_cas = df_cas.groupby(['year', 'epi_week']).count()\n",
    "epi_cas = epi_cas.rename(columns = {'EDAD':'total_casos'})\n",
    "\n",
    "epi_cas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Unir los dataframes de fallecidos y dosis de vacuna por año y semana epidemiológica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unimos ambos dataframes por semana epidemiológica\n",
    "epiweeks = pd.concat([epi_cas, epi_fal, vac_dose], axis=1)  \n",
    "\n",
    "epiweeks = epiweeks.fillna(value = 0) # Rellenamos vacíos o Nan values con 0\n",
    "del epi_cas, epi_fal, vac_dose, df_vac\n",
    "\n",
    "# Cambiamos a int ya que existen Nan values y cambia a float64 automáticamente\n",
    "epiweeks = epiweeks.astype('int64')\n",
    "\n",
    "# Rename columns\n",
    "epiweeks.rename(columns={1: 'total_dosis_1', 2: 'total_dosis_2', 3: 'total_dosis_3'}, inplace=True)\n",
    "                                    \n",
    "epiweeks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obteniendo el número de muertes confirmadas y vacunados contra COVID-19 por semana epidemiológica de cada uno de los 24 departamentos del Perú "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Realizar una crosstab de fallecidos por COVID-19 por departamento de Perú, para cada año y semana epidemiológica\n",
    "\n",
    "Esto se lo realiza para obtener el TOTAL de fallecidos por cada departamento y semana epidemiológica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "falxdep = pd.crosstab(index=[df_fal['year'], df_fal['epi_week']],\n",
    "                      columns=[df_fal['DEPARTAMENTO']],\n",
    "                      margins = False)\n",
    "\n",
    "falxdep = falxdep.add_suffix('_fal')\n",
    "\n",
    "falxdep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn.variable_edad(df_fal, 'EDAD_DECLARADA')\n",
    "del df_fal['DEPARTAMENTO']\n",
    "\n",
    "df_fal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fal_edad = pd.crosstab(index = [df_fal['year'], df_fal['epi_week']], columns= df_fal['edad_cat'])\n",
    "df_fal_edad = df_fal_edad.rename({0: '0_17_fal', 1:'18_29_fal', 2: '30_39_fal', 3:'40_49_fal', 4: '50_59_fal',\n",
    "                                  5:'60_69_fal', 6:'70_79_fal', 7:'80_more_fal'}, axis=1)\n",
    "df_fal_edad.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora tenemos el número de fallecidos por cada departamento y semana epidemiológica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Procesar el dataset de vacunados\n",
    "\n",
    "No existe una manera directa de calcular el total de personas completamente vacunadas por departamento. Para lograrlo se prevee lo siguiente:\n",
    "\n",
    "- El dataset de vacunados (RawData/TB_VACUNACION_COVID19.csv) solo proporciona información sobre el centro de vacunación llamado **'id_centro_vacunacion'**. NO el departamento.\n",
    "\n",
    "- El dataset de los centros de vacunación [(RawData/TB_CENTRO_VACUNACION.csv)]() se puede utilizar para hacer **\"match\"** del **'id_centro_vacunacion'** del dataset de vacunados con la variable **'id_ubigeo'**. Que es una variable numérica de 0 a 1894 que representa a cada distrito.\n",
    "\n",
    "- Finalmente, con el dataset de UBIGEO [(RawData/TB_UBIGEOS.csv)]() es posible reemplazar a cada **'id_ubigeo'** con el departamento respectivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se lee otro dataset porque es más eficiente que separar y crear otro\n",
    "vac_col = ['fecha_vacunacion','dosis', 'id_eess', 'edad']\n",
    "df_vac = dd.read_csv(vac_url, sep = \",\", usecols = vac_col, \n",
    "                     dtype = {'fecha_vacunacion':'int32', 'dosis': 'int8','id_eess':'int32', 'edad': 'float64'})\n",
    "del vac_col\n",
    "\n",
    "df_vac = df_vac.dropna() # Drop nan values\n",
    "df_vac['edad'] = df_vac['edad'].astype('int8')\n",
    "\n",
    "# Dejar solamente a personas con 2 dosis (será el dataset para el dataset en departamentos)\n",
    "df_vac = df_vac[df_vac['dosis'] == 2]\n",
    "del df_vac['dosis']\n",
    "\n",
    "# Convertimos a formato fecha la columna 'fecha_vacunacion'\n",
    "df_vac = df_vac.assign(fecha_vacunacion = dd.to_datetime(df_vac[\"fecha_vacunacion\"], format = \"%Y%m%d\", \n",
    "                                                         errors=\"coerce\"))\n",
    "\n",
    "# Obtenemos el año y semana epidemiológica en una sola columna\n",
    "df_vac['epi_date'] = df_vac['fecha_vacunacion'].map(lambda date : Week.fromdate(date).isoformat())\n",
    "del df_vac['fecha_vacunacion']\n",
    "\n",
    "# Se separa la columna obtenida en 2, una para el año y otra para la semana epidemiológica\n",
    "df_vac[['year','epi_week']] = df_vac['epi_date'].str.split(\"W\", 1, expand=True)\n",
    "del df_vac['epi_date']\n",
    "\n",
    "# Cambiamos el tipo de variable para consumir menos recursos\n",
    "df_vac['year'] = df_vac['year'].astype('int16')\n",
    "df_vac['epi_week'] = df_vac['epi_week'].astype('int8')\n",
    "\n",
    "\n",
    "def edad_cat(df, col):\n",
    "    \"\"\"Función para categorizar edad\"\"\"\n",
    "\n",
    "    conditions = [(df[col]< 18),\n",
    "                  (df[col]>=18) & (df[col]<30),\n",
    "                  (df[col]>=30) & (df[col]<40),\n",
    "                  (df[col]>=40) & (df[col]<50),\n",
    "                  (df[col]>=50) & (df[col]<60),\n",
    "                  (df[col]>=60) & (df[col]<70),\n",
    "                  (df[col]>=70) & (df[col]<80),\n",
    "                  (df[col]>=80)]\n",
    "    choices = [0,1,2,3,4,5,6,7]\n",
    "\n",
    "    return np.select(conditions, choices, default=np.nan).astype('int8')\n",
    "\n",
    "df_vac['edad_cat'] = df_vac.map_partitions(edad_cat, 'edad')\n",
    "del df_vac['edad']\n",
    "\n",
    "df_vac.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crosstab4dask(ddf):\n",
    "    \"\"\"Función que recibe un dask dataframe (ddf) y realiza conteos de variables en cada partición\n",
    "    y devuelve el total por los index que hayamos ingresado, en este caso 'year' y 'epi_week'.\"\"\"\n",
    "    \n",
    "    lst = [] # Lista para almacenar la sumatoria de cada particion\n",
    "\n",
    "    for i in range(0, ddf.npartitions):\n",
    "        ddf = df_vac.partitions[i].compute()\n",
    "        lst.append(pd.crosstab(index=[ddf['year'],ddf['epi_week']], columns = ddf['edad_cat']))\n",
    "\n",
    "    merged_epivac = pd.concat(lst, axis=1)  # Merge all dfs\n",
    "    del lst\n",
    "\n",
    "    merged_epivac = merged_epivac.fillna(0).astype(np.int64)\n",
    "    merged_epivac = merged_epivac.groupby(level=0, axis=1).sum()\n",
    "    \n",
    "    return merged_epivac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vac_edad = crosstab4dask(df_vac)\n",
    "df_vac_edad = df_vac_edad.rename({0: '0_17_vac', 1:'18_29_vac', 2: '30_39_vac', 3:'40_49_vac', 4: '50_59_vac',\n",
    "                                  5:'60_69_vac', 6:'70_79_vac', 7:'80_more_vac'}, axis=1)\n",
    "df_vac_edad.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Procesar los datasets de **UBIGEO** y **CENTROS DE VACUNACIÓN**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.1. Leer y procesar los datasets\n",
    "\n",
    "Para el dataset de UBIGEO solo se necesita las columnas 'id_ubigeo' y 'departamento'. Para el dataset de CENTROS DE VACUNACIÓN solo se necesitan las columnas 'id_centro de vacunación' e 'id_ubigeo'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ubigeo_url = 'RawData/TB_UBIGEOS.csv'\n",
    "vaccenter_url = 'RawData/TB_EESS.csv'\n",
    "\n",
    "# Leemos los datasets de ubigeo y centros de vacunación\n",
    "ubigeo = pd.read_csv(ubigeo_url, usecols = ['id_ubigeo', 'departamento'])\n",
    "vaccenter = pd.read_csv(vaccenter_url, usecols= ['id_eess','id_ubigeo'])\n",
    "\n",
    "# Unimos ambos dataset mediante 'id_ubigeo'\n",
    "vaccenter = vaccenter.merge(ubigeo, on = 'id_ubigeo', how = 'left')\n",
    "del ubigeo, vaccenter['id_ubigeo']\n",
    "\n",
    "vaccenter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora con el nuevo dataset **(vaccenter)** es posible encontrar el departamento correspondiente a 'id_centro de vacunacion' del dataset de vacunados **(df_vac)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.3. Encontrar el departamento correspondiente de todas las personas vacunadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vac = df_vac.merge(vaccenter, on = 'id_eess', how = 'left')\n",
    "del df_vac['id_eess']\n",
    "del vaccenter\n",
    "\n",
    "df_vac.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Crosstab del número de dosis (1,2 y 3) respecto al año y semana epidemiológica\n",
    "\n",
    "**Nota:** No se puede usar multi-index en pivot_table para dask, debido a eso se crea la función **'crosstab4dask'**. Aún es necesario buscar en dask funciones para iterar todas las particiones más facilmente y optimizar el script **(Pendiente)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crosstab4dask(ddf):\n",
    "    \"\"\"Función que recibe un dask dataframe (ddf) y realiza conteos de variables en cada partición\n",
    "    y devuelve el total por los index que hayamos ingresado, en este caso 'year' y 'epi_week'.\"\"\"\n",
    "    \n",
    "    lst = [] # Lista para almacenar la sumatoria de cada particion\n",
    "\n",
    "    for i in range(0, ddf.npartitions):\n",
    "        ddf = df_vac.partitions[i].compute()\n",
    "        lst.append(pd.crosstab(index=[ddf['year'],ddf['epi_week']], columns = ddf['departamento']))\n",
    "\n",
    "    merged_epivac = pd.concat(lst, axis=1)  # Merge all dfs\n",
    "    del lst\n",
    "\n",
    "    merged_epivac = merged_epivac.fillna(0).astype(np.int64)\n",
    "    merged_epivac = merged_epivac.groupby(level=0, axis=1).sum()\n",
    "    \n",
    "    return merged_epivac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vac_dose = crosstab4dask(df_vac)\n",
    "del df_vac\n",
    "\n",
    "vac_dose = vac_dose.add_suffix('_vac')\n",
    "vac_dose.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "falvac_dep = pd.concat([falxdep, vac_dose], axis = 1).fillna(0)\n",
    "falvac_dep.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Unir ambos dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epiweeks_final = pd.concat([epiweeks, df_fal_edad, df_vac_edad, falvac_dep, ], axis = 1).fillna(0).astype('int64')\n",
    "epiweeks_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Guardar el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epiweeks_final.to_csv('Data/DP1_vacunados_y_fallecidos_x_semanaEpi.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente se guarda el dataset final con el ['Total de vacunados y fallecidos por año y semana epidemiológica'](https://github.com/xxotto/covid19-peru/blob/main/Data/TOTAL_vacunados_y_fallecidos_x_semanaEpi.csv) de todo el Perú.\n",
    "\n",
    "Disponible en el directorio [Data](https://github.com/xxotto/covid19-peru/tree/main/Data)."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c5969b0444520e9aeee25788533910dfe0ee1a9ff4ff2cc0b07d55f5d197aaba"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
