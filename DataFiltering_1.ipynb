{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obteniendo el **TOTAL de vacunados y fallecidos** por COVID-19 por cada **semana epidemiológica** de todo el Perú"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Cargar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import functions as fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cargamos direcciones de RawData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vac_url = 'RawData/TB_VACUNACION_COVID19.csv'\n",
    "fal_url = 'RawData/fallecidos_covid.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Procesamos el dataset de fallecidos\n",
    "\n",
    "### 2.1. Leemos el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   FECHA_FALLECIMIENTO\n",
      "0             20210425\n",
      "1             20210428\n",
      "2             20210430\n",
      "3             20210421\n",
      "4             20210803\n"
     ]
    }
   ],
   "source": [
    "fal_col = ['FECHA_FALLECIMIENTO']\n",
    "df_fal = fn.read_largeCSV_file(fal_url, ';', fal_col)\n",
    "print(df_fal.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Procesamos el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   fallecidos\n",
      "epi_year epi_week            \n",
      "2020     10                 2\n",
      "         11                 3\n",
      "         12                30\n",
      "         13                62\n",
      "         14               223\n"
     ]
    }
   ],
   "source": [
    "fn.variable_fecha(df_fal, 'FECHA_FALLECIMIENTO') # Formato fecha en columna 'FECHA_FALLECIMIENTO'\n",
    "fn.date_to_epiweek(df_fal,'FECHA_FALLECIMIENTO') # Obtenemos año y semana epidemiológica de fallecidos  \n",
    "\n",
    "df_fal['fallecido'] = 1 # Contador de casos (cada 1 es un fallecido)                                      \n",
    "df_fal['fallecido'].apply(np.int8)\n",
    "\n",
    "# Devuelve un dataframe con el total de FALLECIDOS por semana y año epidemiológico\n",
    "epi_fal = pd.crosstab(index=[df_fal['epi_year'], df_fal['epi_week']],\n",
    "                      columns=df_fal['fallecido'])\n",
    "\n",
    "epi_fal.columns = ['fallecidos'] # Renombramos\n",
    "\n",
    "del df_fal\n",
    "print(epi_fal.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Procesamos el dataset de vacunados\n",
    "\n",
    "### 3.1. Leemos el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  fecha_vacunacion  dosis\n",
      "0       19/07/2021      2\n",
      "1       17/06/2021      2\n",
      "2       11/06/2021      2\n",
      "3       28/07/2021      2\n",
      "4        8/05/2021      1\n"
     ]
    }
   ],
   "source": [
    "vac_col = ['fecha_vacunacion','dosis']  # Seleccionar solamente la columna de fechas de ambos datasets \n",
    "df_vac = fn.read_largeCSV_file(vac_url, ',', vac_col)   # Leemos los datasets \n",
    "print(df_vac.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Procesamos el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   epi_year  epi_week  vacunado\n",
      "0      2021        29         1\n",
      "1      2021        24         1\n",
      "2      2021        23         1\n",
      "3      2021        30         1\n",
      "7      2021        22         1\n"
     ]
    }
   ],
   "source": [
    "# Convertimos el dataset de vacunados en una lista de chunks o dfs\n",
    "# (Para procesar información en bloques de 500 000) \n",
    "lst_vac = fn.df_into_chunks(df_vac)\n",
    "del df_vac\n",
    "\n",
    "# Que cada 'chunk' de lst_vac sea solamente cuando dosis = 2, es decir tengan 2 dosis\n",
    "lst_vac = [chunk.loc[chunk.loc[:, 'dosis'] == 2] for chunk in lst_vac]\n",
    "\n",
    "# Convertir a formato fecha la columna 'fecha vacunacion' y obtener su año y semana epi\n",
    "[fn.variable_fecha_ymd(chunk, 'fecha_vacunacion') for chunk in lst_vac]\n",
    "[fn.date_to_epiweek(chunk, 'fecha_vacunacion') for chunk in lst_vac]\n",
    "\n",
    "# Creamos columnas de 1 en cada chunk para contabilizar cada caso de vacunado\n",
    "for chunk in lst_vac:                                        \n",
    "    chunk['vacunado'] = 1\n",
    "    chunk['vacunado'].apply(np.int8)\n",
    "    del chunk['dosis']  # Borramos columna dosis llena de número 2\n",
    "del chunk # Borramos el último chunk que queda al final\n",
    "\n",
    "print(lst_vac[0].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   vacunados\n",
      "epi_year epi_week           \n",
      "2021     6               1.0\n",
      "         7               4.0\n",
      "         8              19.0\n",
      "         9           93044.0\n",
      "         10          80891.0\n"
     ]
    }
   ],
   "source": [
    "def epiweeks_chunks(dfs_vac):\n",
    "    \"\"\"\n",
    "    Devuelve un dataframe con el total de VACUNADOS por semana y año \n",
    "    epidemiológico (recibe una lista de dataframes o chunks)\n",
    "    \"\"\"\n",
    "    var_holder = {}     # Diccionario para guardar nombres                                             \n",
    "    lst_epi_vac = []    # Lista de dfs para cada sumatoria de chunks\n",
    "                                         \n",
    "    for i, chunk in enumerate(dfs_vac):\n",
    "        var_holder['epi_vac_' + str(i)]= pd.crosstab(index=[chunk['epi_year'],\n",
    "                                                            chunk['epi_week']],\n",
    "                                                     columns=chunk['vacunado'])\n",
    "        lst_epi_vac.append(var_holder['epi_vac_' + str(i)])\n",
    "        \n",
    "    # Unimos todos los dfs sumados en uno solo\n",
    "    merged_epivac = pd.concat(lst_epi_vac, axis=1) \n",
    "    epi_vac = pd.DataFrame(merged_epivac.sum(numeric_only=True, axis=1))\n",
    "    epi_vac.columns = ['vacunados']\n",
    "    \n",
    "    return epi_vac\n",
    "\n",
    "epi_vac = epiweeks_chunks(lst_vac)\n",
    "del lst_vac\n",
    "print(epi_vac.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Unimos el dataset del TOTAL de vacunados (2 dosis) y TOTAL de fallecidos por su semana epidemiológica y año"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   deceased  vaccinated\n",
      "epi_year epi_week                      \n",
      "2020     10               2           0\n",
      "         11               3           0\n",
      "         12              30           0\n",
      "         13              62           0\n",
      "         14             223           0\n"
     ]
    }
   ],
   "source": [
    "# Concatenamos ambos dataframes por columnas\n",
    "merged_epiweeks = pd.concat([epi_fal, epi_vac], axis=1)         \n",
    "merged_epiweeks = merged_epiweeks.fillna(value = 0) # Rellenamos vacíos o Nan values con 0\n",
    "\n",
    "# Cambiamos a Int64 ya que existen Nan values y cambia a float64 automáticamente\n",
    "merged_epiweeks = merged_epiweeks.astype('Int64')\n",
    "merged_epiweeks = merged_epiweeks.rename({'fallecidos': 'deceased', \n",
    "                                          'vacunados': 'vaccinated'}, axis=1) # Renombrar columnas\n",
    "                                          \n",
    "print(merged_epiweeks.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Guardar el dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_epiweeks.to_csv('Data/TOTAL_vacunados_y_fallecidos_x_semanaEpi.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c5969b0444520e9aeee25788533910dfe0ee1a9ff4ff2cc0b07d55f5d197aaba"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
